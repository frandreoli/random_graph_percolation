{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and plotting graph-percolation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory is:  c:\\Users\\fandreoli\\Github Repos\\random_graph_percolation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#%cd \"C:/Users/fandreoli/Github Repos/random_graph_percolation\"\n",
    "print(\"The working directory is: \", str(os.getcwd()))\n",
    "data_dir = \"Data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph size choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_nodes = (10**7)\n",
    "override_data = [True, False][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the C script to compute the data.\n",
      "Script completed in  00:02:03\n",
      "Compilation time:  00:00:00\n",
      "Execution time:  00:02:02\n"
     ]
    }
   ],
   "source": [
    "def time_display(time_sec):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(time_sec ))\n",
    "\n",
    "def dir_create(dir_path):\n",
    "    try:\n",
    "        os.mkdir(dir_path)\n",
    "        print(f\"Created directory '{dir_path}'.\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to create '{dir_path}'.\")\n",
    "    except Exception as e:\n",
    "        raise(f\"When creating {dir_path}, the following error occurred: {e}\")\n",
    "\n",
    "if \"g_mean_\"+str(N_nodes)+\".dat\" in set(os.listdir(data_dir)) and not override_data:\n",
    "    print(\"The data have already been computed.\")\n",
    "else:\n",
    "    import time\n",
    "    print(\"Executing the C script to compute the data.\")\n",
    "    dir_create(data_dir)\n",
    "    dir_create(data_dir+\"\\\\Temp\")\n",
    "    time_start = time.time()\n",
    "    os.system('gcc random_graph.c -o random_graph.exe')\n",
    "    time_compile = time.time()\n",
    "    os.system('random_graph.exe '+str(N_nodes)+' '+data_dir)\n",
    "    time_end = time.time()\n",
    "    print(\"Script completed in \",time_display(time_end-time_start))\n",
    "    print(\"Compilation time: \",time_display(time_compile-time_start))\n",
    "    print(\"Execution time: \",time_display(time_end-time_compile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the data to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "graph_sizes = [int(10**pow) for pow in range(2,8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes to analyze:  [100, 1000, 10000, 100000, 1000000, 10000000]\n"
     ]
    }
   ],
   "source": [
    "def size_file_extract(current_file):\n",
    "    return int(current_file.replace(\"g_mean_\",\"\").replace(\".dat\",\"\"))\n",
    "    \n",
    "file_names = [\"g_mean_\"+str(sizes)+\".dat\" for sizes in graph_sizes]\n",
    "file_names = set(file_names) & set(os.listdir(data_dir))\n",
    "file_names = list(file_names)\n",
    "file_names.sort()\n",
    "graph_sizes = [size_file_extract(current_file) for current_file in file_names]\n",
    "print(\"Sizes to analyze: \", graph_sizes)\n",
    "\n",
    "sol_df=dict({})\n",
    "for i,current_file in enumerate(file_names):\n",
    "    size = graph_sizes[i]\n",
    "    current_file = data_dir+current_file\n",
    "    try:\n",
    "        sol_df[size] = pd.read_csv(current_file, delimiter=\",\")\n",
    "    except Exception as error_here:\n",
    "        print(\"You got an error when either parsing the data file:\", current_file)\n",
    "        raise(error_here)\n",
    "    sol_df[size].columns = [col.replace(\" \", \"\") for col in sol_df[size].columns]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in graph_sizes:\n",
    "    plt.plot(sol_df[size]['c'], sol_df[size]['Smax_mean'],label=\"N$ = 10^{{{}}}$\".format(round(np.log10(size))))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"B / N\")\n",
    "plt.ylabel(\"S$_{max}$ / N\")\n",
    "plt.title(\"Super-cluster fraction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_transition_list = pd.DataFrame({\"N\":graph_sizes,\"S*_max\":[0.0 for _ in range(0,len(graph_sizes))]})\n",
    "for i,size in enumerate(graph_sizes):\n",
    "    val = sol_df[size].sort_values(by='c', key=lambda val: abs(val-0.5))['Smax_mean'][0]\n",
    "    phase_transition_list.loc[i, \"S_max\"] = val\n",
    "    \n",
    "plt.loglog(phase_transition_list['N'],phase_transition_list['S_max'])\n",
    "\n",
    "fit_array = np.polyfit(np.log10(phase_transition_list['N']),np.log10(phase_transition_list['S_max']),1)\n",
    "x_fit_range = np.arange(min(np.log10(graph_sizes)),max(np.log10(graph_sizes)),0.01)\n",
    "y_fit_range = np.array([(lambda y :fit_array[1]+y*fit_array[0] )(x) for x in x_fit_range])\n",
    "plt.loglog(10**x_fit_range,10**y_fit_range, linestyle=':', color='black')\n",
    "\n",
    "plt.scatter(phase_transition_list['N'],phase_transition_list['S_max'])\n",
    "\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"S$_{max}$(B/N = 0.5)\")\n",
    "plt.title(\"Super-cluster fraction at B/N = 0.5\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "def decimal_round(num,digits=1):\n",
    "    return round(num*10**digits)/10**digits\n",
    "print(\"The scaling is \"+str(decimal_round(10**fit_array[1]))+\"*N^(\"+str(decimal_round(fit_array[0]))+\")\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
